{"ast":null,"code":"/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\nimport * as arrays from '../../../base/common/arrays.js';\nimport { onUnexpectedError } from '../../../base/common/errors.js';\nimport { LineTokens } from '../tokens/lineTokens.js';\nimport { TokenizationRegistry } from '../languages.js';\nimport { nullTokenizeEncoded } from '../languages/nullTokenize.js';\nimport { Disposable } from '../../../base/common/lifecycle.js';\nimport { StopWatch } from '../../../base/common/stopwatch.js';\nimport { countEOL } from '../core/eolCounter.js';\nimport { ContiguousMultilineTokensBuilder } from '../tokens/contiguousMultilineTokensBuilder.js';\nimport { runWhenIdle } from '../../../base/common/async.js';\nimport { setTimeout0 } from '../../../base/common/platform.js';\n/**\n * An array that avoids being sparse by always\n * filling up unused indices with a default value.\n */\nclass ContiguousGrowingArray {\n  constructor(_default) {\n    this._default = _default;\n    this._store = [];\n  }\n  get(index) {\n    if (index < this._store.length) {\n      return this._store[index];\n    }\n    return this._default;\n  }\n  set(index, value) {\n    while (index >= this._store.length) {\n      this._store[this._store.length] = this._default;\n    }\n    this._store[index] = value;\n  }\n  delete(deleteIndex, deleteCount) {\n    if (deleteCount === 0 || deleteIndex >= this._store.length) {\n      return;\n    }\n    this._store.splice(deleteIndex, deleteCount);\n  }\n  insert(insertIndex, insertCount) {\n    if (insertCount === 0 || insertIndex >= this._store.length) {\n      return;\n    }\n    const arr = [];\n    for (let i = 0; i < insertCount; i++) {\n      arr[i] = this._default;\n    }\n    this._store = arrays.arrayInsert(this._store, insertIndex, arr);\n  }\n}\n/**\n * Stores the states at the start of each line and keeps track of which lines\n * must be retokenized. Also uses state equality to quickly validate lines\n * that don't need to be retokenized.\n *\n * For example, when typing on a line, the line gets marked as needing to be tokenized.\n * Once the line is tokenized, the end state is checked for equality against the begin\n * state of the next line. If the states are equal, tokenization doesn't need to run\n * again over the rest of the file. If the states are not equal, the next line gets marked\n * as needing to be tokenized.\n */\nexport class TokenizationStateStore {\n  constructor(tokenizationSupport, initialState) {\n    this.tokenizationSupport = tokenizationSupport;\n    this.initialState = initialState;\n    /**\n     * `lineBeginState[i]` contains the begin state used to tokenize line number `i + 1`.\n     */\n    this._lineBeginState = new ContiguousGrowingArray(null);\n    /**\n     * `lineNeedsTokenization[i]` describes if line number `i + 1` needs to be tokenized.\n     */\n    this._lineNeedsTokenization = new ContiguousGrowingArray(true);\n    this._firstLineNeedsTokenization = 0;\n    this._lineBeginState.set(0, this.initialState);\n  }\n  get invalidLineStartIndex() {\n    return this._firstLineNeedsTokenization;\n  }\n  markMustBeTokenized(lineIndex) {\n    this._lineNeedsTokenization.set(lineIndex, true);\n    this._firstLineNeedsTokenization = Math.min(this._firstLineNeedsTokenization, lineIndex);\n  }\n  getBeginState(lineIndex) {\n    return this._lineBeginState.get(lineIndex);\n  }\n  setEndState(linesLength, lineIndex, endState) {\n    this._lineNeedsTokenization.set(lineIndex, false);\n    this._firstLineNeedsTokenization = lineIndex + 1;\n    // Check if this was the last line\n    if (lineIndex === linesLength - 1) {\n      return;\n    }\n    // Check if the end state has changed\n    const previousEndState = this._lineBeginState.get(lineIndex + 1);\n    if (previousEndState === null || !endState.equals(previousEndState)) {\n      this._lineBeginState.set(lineIndex + 1, endState);\n      this.markMustBeTokenized(lineIndex + 1);\n      return;\n    }\n    // Perhaps we can skip tokenizing some lines...\n    let i = lineIndex + 1;\n    while (i < linesLength) {\n      if (this._lineNeedsTokenization.get(i)) {\n        break;\n      }\n      i++;\n    }\n    this._firstLineNeedsTokenization = i;\n  }\n  //#region Editing\n  applyEdits(range, eolCount) {\n    this.markMustBeTokenized(range.startLineNumber - 1);\n    this._lineBeginState.delete(range.startLineNumber, range.endLineNumber - range.startLineNumber);\n    this._lineNeedsTokenization.delete(range.startLineNumber, range.endLineNumber - range.startLineNumber);\n    this._lineBeginState.insert(range.startLineNumber, eolCount);\n    this._lineNeedsTokenization.insert(range.startLineNumber, eolCount);\n  }\n}\nexport class TextModelTokenization extends Disposable {\n  constructor(_textModel, _tokenizationPart, _languageIdCodec) {\n    super();\n    this._textModel = _textModel;\n    this._tokenizationPart = _tokenizationPart;\n    this._languageIdCodec = _languageIdCodec;\n    this._isScheduled = false;\n    this._isDisposed = false;\n    this._tokenizationStateStore = null;\n    this._register(TokenizationRegistry.onDidChange(e => {\n      const languageId = this._textModel.getLanguageId();\n      if (e.changedLanguages.indexOf(languageId) === -1) {\n        return;\n      }\n      this._resetTokenizationState();\n      this._tokenizationPart.clearTokens();\n    }));\n    this._resetTokenizationState();\n  }\n  dispose() {\n    this._isDisposed = true;\n    super.dispose();\n  }\n  //#region TextModel events\n  handleDidChangeContent(e) {\n    if (e.isFlush) {\n      this._resetTokenizationState();\n      return;\n    }\n    if (this._tokenizationStateStore) {\n      for (let i = 0, len = e.changes.length; i < len; i++) {\n        const change = e.changes[i];\n        const [eolCount] = countEOL(change.text);\n        this._tokenizationStateStore.applyEdits(change.range, eolCount);\n      }\n    }\n    this._beginBackgroundTokenization();\n  }\n  handleDidChangeAttached() {\n    this._beginBackgroundTokenization();\n  }\n  handleDidChangeLanguage(e) {\n    this._resetTokenizationState();\n    this._tokenizationPart.clearTokens();\n  }\n  //#endregion\n  _resetTokenizationState() {\n    const [tokenizationSupport, initialState] = initializeTokenization(this._textModel, this._tokenizationPart);\n    if (tokenizationSupport && initialState) {\n      this._tokenizationStateStore = new TokenizationStateStore(tokenizationSupport, initialState);\n    } else {\n      this._tokenizationStateStore = null;\n    }\n    this._beginBackgroundTokenization();\n  }\n  _beginBackgroundTokenization() {\n    if (this._isScheduled || !this._textModel.isAttachedToEditor() || !this._hasLinesToTokenize()) {\n      return;\n    }\n    this._isScheduled = true;\n    runWhenIdle(deadline => {\n      this._isScheduled = false;\n      this._backgroundTokenizeWithDeadline(deadline);\n    });\n  }\n  /**\n   * Tokenize until the deadline occurs, but try to yield every 1-2ms.\n   */\n  _backgroundTokenizeWithDeadline(deadline) {\n    // Read the time remaining from the `deadline` immediately because it is unclear\n    // if the `deadline` object will be valid after execution leaves this function.\n    const endTime = Date.now() + deadline.timeRemaining();\n    const execute = () => {\n      if (this._isDisposed || !this._textModel.isAttachedToEditor() || !this._hasLinesToTokenize()) {\n        // disposed in the meantime or detached or finished\n        return;\n      }\n      this._backgroundTokenizeForAtLeast1ms();\n      if (Date.now() < endTime) {\n        // There is still time before reaching the deadline, so yield to the browser and then\n        // continue execution\n        setTimeout0(execute);\n      } else {\n        // The deadline has been reached, so schedule a new idle callback if necessary\n        this._beginBackgroundTokenization();\n      }\n    };\n    execute();\n  }\n  /**\n   * Tokenize for at least 1ms.\n   */\n  _backgroundTokenizeForAtLeast1ms() {\n    const lineCount = this._textModel.getLineCount();\n    const builder = new ContiguousMultilineTokensBuilder();\n    const sw = StopWatch.create(false);\n    do {\n      if (sw.elapsed() > 1) {\n        // the comparison is intentionally > 1 and not >= 1 to ensure that\n        // a full millisecond has elapsed, given how microseconds are rounded\n        // to milliseconds\n        break;\n      }\n      const tokenizedLineNumber = this._tokenizeOneInvalidLine(builder);\n      if (tokenizedLineNumber >= lineCount) {\n        break;\n      }\n    } while (this._hasLinesToTokenize());\n    this._tokenizationPart.setTokens(builder.finalize(), this._isTokenizationComplete());\n  }\n  tokenizeViewport(startLineNumber, endLineNumber) {\n    const builder = new ContiguousMultilineTokensBuilder();\n    this._tokenizeViewport(builder, startLineNumber, endLineNumber);\n    this._tokenizationPart.setTokens(builder.finalize(), this._isTokenizationComplete());\n  }\n  reset() {\n    this._resetTokenizationState();\n    this._tokenizationPart.clearTokens();\n  }\n  forceTokenization(lineNumber) {\n    const builder = new ContiguousMultilineTokensBuilder();\n    this._updateTokensUntilLine(builder, lineNumber);\n    this._tokenizationPart.setTokens(builder.finalize(), this._isTokenizationComplete());\n  }\n  getTokenTypeIfInsertingCharacter(position, character) {\n    if (!this._tokenizationStateStore) {\n      return 0 /* StandardTokenType.Other */;\n    }\n\n    this.forceTokenization(position.lineNumber);\n    const lineStartState = this._tokenizationStateStore.getBeginState(position.lineNumber - 1);\n    if (!lineStartState) {\n      return 0 /* StandardTokenType.Other */;\n    }\n\n    const languageId = this._textModel.getLanguageId();\n    const lineContent = this._textModel.getLineContent(position.lineNumber);\n    // Create the text as if `character` was inserted\n    const text = lineContent.substring(0, position.column - 1) + character + lineContent.substring(position.column - 1);\n    const r = safeTokenize(this._languageIdCodec, languageId, this._tokenizationStateStore.tokenizationSupport, text, true, lineStartState);\n    const lineTokens = new LineTokens(r.tokens, text, this._languageIdCodec);\n    if (lineTokens.getCount() === 0) {\n      return 0 /* StandardTokenType.Other */;\n    }\n\n    const tokenIndex = lineTokens.findTokenIndexAtOffset(position.column - 1);\n    return lineTokens.getStandardTokenType(tokenIndex);\n  }\n  tokenizeLineWithEdit(position, length, newText) {\n    const lineNumber = position.lineNumber;\n    const column = position.column;\n    if (!this._tokenizationStateStore) {\n      return null;\n    }\n    this.forceTokenization(lineNumber);\n    const lineStartState = this._tokenizationStateStore.getBeginState(lineNumber - 1);\n    if (!lineStartState) {\n      return null;\n    }\n    const curLineContent = this._textModel.getLineContent(lineNumber);\n    const newLineContent = curLineContent.substring(0, column - 1) + newText + curLineContent.substring(column - 1 + length);\n    const languageId = this._textModel.getLanguageIdAtPosition(lineNumber, 0);\n    const result = safeTokenize(this._languageIdCodec, languageId, this._tokenizationStateStore.tokenizationSupport, newLineContent, true, lineStartState);\n    const lineTokens = new LineTokens(result.tokens, newLineContent, this._languageIdCodec);\n    return lineTokens;\n  }\n  isCheapToTokenize(lineNumber) {\n    if (!this._tokenizationStateStore) {\n      return true;\n    }\n    const firstInvalidLineNumber = this._tokenizationStateStore.invalidLineStartIndex + 1;\n    if (lineNumber > firstInvalidLineNumber) {\n      return false;\n    }\n    if (lineNumber < firstInvalidLineNumber) {\n      return true;\n    }\n    if (this._textModel.getLineLength(lineNumber) < 2048 /* Constants.CHEAP_TOKENIZATION_LENGTH_LIMIT */) {\n      return true;\n    }\n    return false;\n  }\n  _hasLinesToTokenize() {\n    if (!this._tokenizationStateStore) {\n      return false;\n    }\n    return this._tokenizationStateStore.invalidLineStartIndex < this._textModel.getLineCount();\n  }\n  _isTokenizationComplete() {\n    if (!this._tokenizationStateStore) {\n      return false;\n    }\n    return this._tokenizationStateStore.invalidLineStartIndex >= this._textModel.getLineCount();\n  }\n  _tokenizeOneInvalidLine(builder) {\n    if (!this._tokenizationStateStore || !this._hasLinesToTokenize()) {\n      return this._textModel.getLineCount() + 1;\n    }\n    const lineNumber = this._tokenizationStateStore.invalidLineStartIndex + 1;\n    this._updateTokensUntilLine(builder, lineNumber);\n    return lineNumber;\n  }\n  _updateTokensUntilLine(builder, lineNumber) {\n    if (!this._tokenizationStateStore) {\n      return;\n    }\n    const languageId = this._textModel.getLanguageId();\n    const linesLength = this._textModel.getLineCount();\n    const endLineIndex = lineNumber - 1;\n    // Validate all states up to and including endLineIndex\n    for (let lineIndex = this._tokenizationStateStore.invalidLineStartIndex; lineIndex <= endLineIndex; lineIndex++) {\n      const text = this._textModel.getLineContent(lineIndex + 1);\n      const lineStartState = this._tokenizationStateStore.getBeginState(lineIndex);\n      const r = safeTokenize(this._languageIdCodec, languageId, this._tokenizationStateStore.tokenizationSupport, text, true, lineStartState);\n      builder.add(lineIndex + 1, r.tokens);\n      this._tokenizationStateStore.setEndState(linesLength, lineIndex, r.endState);\n      lineIndex = this._tokenizationStateStore.invalidLineStartIndex - 1; // -1 because the outer loop increments it\n    }\n  }\n\n  _tokenizeViewport(builder, startLineNumber, endLineNumber) {\n    if (!this._tokenizationStateStore) {\n      // nothing to do\n      return;\n    }\n    if (endLineNumber <= this._tokenizationStateStore.invalidLineStartIndex) {\n      // nothing to do\n      return;\n    }\n    if (startLineNumber <= this._tokenizationStateStore.invalidLineStartIndex) {\n      // tokenization has reached the viewport start...\n      this._updateTokensUntilLine(builder, endLineNumber);\n      return;\n    }\n    let nonWhitespaceColumn = this._textModel.getLineFirstNonWhitespaceColumn(startLineNumber);\n    const fakeLines = [];\n    let initialState = null;\n    for (let i = startLineNumber - 1; nonWhitespaceColumn > 1 && i >= 1; i--) {\n      const newNonWhitespaceIndex = this._textModel.getLineFirstNonWhitespaceColumn(i);\n      if (newNonWhitespaceIndex === 0) {\n        continue;\n      }\n      if (newNonWhitespaceIndex < nonWhitespaceColumn) {\n        fakeLines.push(this._textModel.getLineContent(i));\n        nonWhitespaceColumn = newNonWhitespaceIndex;\n        initialState = this._tokenizationStateStore.getBeginState(i - 1);\n        if (initialState) {\n          break;\n        }\n      }\n    }\n    if (!initialState) {\n      initialState = this._tokenizationStateStore.initialState;\n    }\n    const languageId = this._textModel.getLanguageId();\n    let state = initialState;\n    for (let i = fakeLines.length - 1; i >= 0; i--) {\n      const r = safeTokenize(this._languageIdCodec, languageId, this._tokenizationStateStore.tokenizationSupport, fakeLines[i], false, state);\n      state = r.endState;\n    }\n    for (let lineNumber = startLineNumber; lineNumber <= endLineNumber; lineNumber++) {\n      const text = this._textModel.getLineContent(lineNumber);\n      const r = safeTokenize(this._languageIdCodec, languageId, this._tokenizationStateStore.tokenizationSupport, text, true, state);\n      builder.add(lineNumber, r.tokens);\n      this._tokenizationStateStore.markMustBeTokenized(lineNumber - 1);\n      state = r.endState;\n    }\n  }\n}\nfunction initializeTokenization(textModel, tokenizationPart) {\n  if (textModel.isTooLargeForTokenization()) {\n    return [null, null];\n  }\n  const tokenizationSupport = TokenizationRegistry.get(tokenizationPart.getLanguageId());\n  if (!tokenizationSupport) {\n    return [null, null];\n  }\n  let initialState;\n  try {\n    initialState = tokenizationSupport.getInitialState();\n  } catch (e) {\n    onUnexpectedError(e);\n    return [null, null];\n  }\n  return [tokenizationSupport, initialState];\n}\nfunction safeTokenize(languageIdCodec, languageId, tokenizationSupport, text, hasEOL, state) {\n  let r = null;\n  if (tokenizationSupport) {\n    try {\n      r = tokenizationSupport.tokenizeEncoded(text, hasEOL, state.clone());\n    } catch (e) {\n      onUnexpectedError(e);\n    }\n  }\n  if (!r) {\n    r = nullTokenizeEncoded(languageIdCodec.encodeLanguageId(languageId), state);\n  }\n  LineTokens.convertToEndOffset(r.tokens, text.length);\n  return r;\n}","map":{"version":3,"names":["arrays","onUnexpectedError","LineTokens","TokenizationRegistry","nullTokenizeEncoded","Disposable","StopWatch","countEOL","ContiguousMultilineTokensBuilder","runWhenIdle","setTimeout0","ContiguousGrowingArray","constructor","_default","_store","get","index","length","set","value","delete","deleteIndex","deleteCount","splice","insert","insertIndex","insertCount","arr","i","arrayInsert","TokenizationStateStore","tokenizationSupport","initialState","_lineBeginState","_lineNeedsTokenization","_firstLineNeedsTokenization","invalidLineStartIndex","markMustBeTokenized","lineIndex","Math","min","getBeginState","setEndState","linesLength","endState","previousEndState","equals","applyEdits","range","eolCount","startLineNumber","endLineNumber","TextModelTokenization","_textModel","_tokenizationPart","_languageIdCodec","_isScheduled","_isDisposed","_tokenizationStateStore","_register","onDidChange","e","languageId","getLanguageId","changedLanguages","indexOf","_resetTokenizationState","clearTokens","dispose","handleDidChangeContent","isFlush","len","changes","change","text","_beginBackgroundTokenization","handleDidChangeAttached","handleDidChangeLanguage","initializeTokenization","isAttachedToEditor","_hasLinesToTokenize","deadline","_backgroundTokenizeWithDeadline","endTime","Date","now","timeRemaining","execute","_backgroundTokenizeForAtLeast1ms","lineCount","getLineCount","builder","sw","create","elapsed","tokenizedLineNumber","_tokenizeOneInvalidLine","setTokens","finalize","_isTokenizationComplete","tokenizeViewport","_tokenizeViewport","reset","forceTokenization","lineNumber","_updateTokensUntilLine","getTokenTypeIfInsertingCharacter","position","character","lineStartState","lineContent","getLineContent","substring","column","r","safeTokenize","lineTokens","tokens","getCount","tokenIndex","findTokenIndexAtOffset","getStandardTokenType","tokenizeLineWithEdit","newText","curLineContent","newLineContent","getLanguageIdAtPosition","result","isCheapToTokenize","firstInvalidLineNumber","getLineLength","endLineIndex","add","nonWhitespaceColumn","getLineFirstNonWhitespaceColumn","fakeLines","newNonWhitespaceIndex","push","state","textModel","tokenizationPart","isTooLargeForTokenization","getInitialState","languageIdCodec","hasEOL","tokenizeEncoded","clone","encodeLanguageId","convertToEndOffset"],"sources":["/home/deathblade287/Desktop/AI-MODELS-TESTING/react-app/node_modules/monaco-editor/esm/vs/editor/common/model/textModelTokens.js"],"sourcesContent":["/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\nimport * as arrays from '../../../base/common/arrays.js';\nimport { onUnexpectedError } from '../../../base/common/errors.js';\nimport { LineTokens } from '../tokens/lineTokens.js';\nimport { TokenizationRegistry } from '../languages.js';\nimport { nullTokenizeEncoded } from '../languages/nullTokenize.js';\nimport { Disposable } from '../../../base/common/lifecycle.js';\nimport { StopWatch } from '../../../base/common/stopwatch.js';\nimport { countEOL } from '../core/eolCounter.js';\nimport { ContiguousMultilineTokensBuilder } from '../tokens/contiguousMultilineTokensBuilder.js';\nimport { runWhenIdle } from '../../../base/common/async.js';\nimport { setTimeout0 } from '../../../base/common/platform.js';\n/**\n * An array that avoids being sparse by always\n * filling up unused indices with a default value.\n */\nclass ContiguousGrowingArray {\n    constructor(_default) {\n        this._default = _default;\n        this._store = [];\n    }\n    get(index) {\n        if (index < this._store.length) {\n            return this._store[index];\n        }\n        return this._default;\n    }\n    set(index, value) {\n        while (index >= this._store.length) {\n            this._store[this._store.length] = this._default;\n        }\n        this._store[index] = value;\n    }\n    delete(deleteIndex, deleteCount) {\n        if (deleteCount === 0 || deleteIndex >= this._store.length) {\n            return;\n        }\n        this._store.splice(deleteIndex, deleteCount);\n    }\n    insert(insertIndex, insertCount) {\n        if (insertCount === 0 || insertIndex >= this._store.length) {\n            return;\n        }\n        const arr = [];\n        for (let i = 0; i < insertCount; i++) {\n            arr[i] = this._default;\n        }\n        this._store = arrays.arrayInsert(this._store, insertIndex, arr);\n    }\n}\n/**\n * Stores the states at the start of each line and keeps track of which lines\n * must be retokenized. Also uses state equality to quickly validate lines\n * that don't need to be retokenized.\n *\n * For example, when typing on a line, the line gets marked as needing to be tokenized.\n * Once the line is tokenized, the end state is checked for equality against the begin\n * state of the next line. If the states are equal, tokenization doesn't need to run\n * again over the rest of the file. If the states are not equal, the next line gets marked\n * as needing to be tokenized.\n */\nexport class TokenizationStateStore {\n    constructor(tokenizationSupport, initialState) {\n        this.tokenizationSupport = tokenizationSupport;\n        this.initialState = initialState;\n        /**\n         * `lineBeginState[i]` contains the begin state used to tokenize line number `i + 1`.\n         */\n        this._lineBeginState = new ContiguousGrowingArray(null);\n        /**\n         * `lineNeedsTokenization[i]` describes if line number `i + 1` needs to be tokenized.\n         */\n        this._lineNeedsTokenization = new ContiguousGrowingArray(true);\n        this._firstLineNeedsTokenization = 0;\n        this._lineBeginState.set(0, this.initialState);\n    }\n    get invalidLineStartIndex() {\n        return this._firstLineNeedsTokenization;\n    }\n    markMustBeTokenized(lineIndex) {\n        this._lineNeedsTokenization.set(lineIndex, true);\n        this._firstLineNeedsTokenization = Math.min(this._firstLineNeedsTokenization, lineIndex);\n    }\n    getBeginState(lineIndex) {\n        return this._lineBeginState.get(lineIndex);\n    }\n    setEndState(linesLength, lineIndex, endState) {\n        this._lineNeedsTokenization.set(lineIndex, false);\n        this._firstLineNeedsTokenization = lineIndex + 1;\n        // Check if this was the last line\n        if (lineIndex === linesLength - 1) {\n            return;\n        }\n        // Check if the end state has changed\n        const previousEndState = this._lineBeginState.get(lineIndex + 1);\n        if (previousEndState === null || !endState.equals(previousEndState)) {\n            this._lineBeginState.set(lineIndex + 1, endState);\n            this.markMustBeTokenized(lineIndex + 1);\n            return;\n        }\n        // Perhaps we can skip tokenizing some lines...\n        let i = lineIndex + 1;\n        while (i < linesLength) {\n            if (this._lineNeedsTokenization.get(i)) {\n                break;\n            }\n            i++;\n        }\n        this._firstLineNeedsTokenization = i;\n    }\n    //#region Editing\n    applyEdits(range, eolCount) {\n        this.markMustBeTokenized(range.startLineNumber - 1);\n        this._lineBeginState.delete(range.startLineNumber, range.endLineNumber - range.startLineNumber);\n        this._lineNeedsTokenization.delete(range.startLineNumber, range.endLineNumber - range.startLineNumber);\n        this._lineBeginState.insert(range.startLineNumber, eolCount);\n        this._lineNeedsTokenization.insert(range.startLineNumber, eolCount);\n    }\n}\nexport class TextModelTokenization extends Disposable {\n    constructor(_textModel, _tokenizationPart, _languageIdCodec) {\n        super();\n        this._textModel = _textModel;\n        this._tokenizationPart = _tokenizationPart;\n        this._languageIdCodec = _languageIdCodec;\n        this._isScheduled = false;\n        this._isDisposed = false;\n        this._tokenizationStateStore = null;\n        this._register(TokenizationRegistry.onDidChange((e) => {\n            const languageId = this._textModel.getLanguageId();\n            if (e.changedLanguages.indexOf(languageId) === -1) {\n                return;\n            }\n            this._resetTokenizationState();\n            this._tokenizationPart.clearTokens();\n        }));\n        this._resetTokenizationState();\n    }\n    dispose() {\n        this._isDisposed = true;\n        super.dispose();\n    }\n    //#region TextModel events\n    handleDidChangeContent(e) {\n        if (e.isFlush) {\n            this._resetTokenizationState();\n            return;\n        }\n        if (this._tokenizationStateStore) {\n            for (let i = 0, len = e.changes.length; i < len; i++) {\n                const change = e.changes[i];\n                const [eolCount] = countEOL(change.text);\n                this._tokenizationStateStore.applyEdits(change.range, eolCount);\n            }\n        }\n        this._beginBackgroundTokenization();\n    }\n    handleDidChangeAttached() {\n        this._beginBackgroundTokenization();\n    }\n    handleDidChangeLanguage(e) {\n        this._resetTokenizationState();\n        this._tokenizationPart.clearTokens();\n    }\n    //#endregion\n    _resetTokenizationState() {\n        const [tokenizationSupport, initialState] = initializeTokenization(this._textModel, this._tokenizationPart);\n        if (tokenizationSupport && initialState) {\n            this._tokenizationStateStore = new TokenizationStateStore(tokenizationSupport, initialState);\n        }\n        else {\n            this._tokenizationStateStore = null;\n        }\n        this._beginBackgroundTokenization();\n    }\n    _beginBackgroundTokenization() {\n        if (this._isScheduled || !this._textModel.isAttachedToEditor() || !this._hasLinesToTokenize()) {\n            return;\n        }\n        this._isScheduled = true;\n        runWhenIdle((deadline) => {\n            this._isScheduled = false;\n            this._backgroundTokenizeWithDeadline(deadline);\n        });\n    }\n    /**\n     * Tokenize until the deadline occurs, but try to yield every 1-2ms.\n     */\n    _backgroundTokenizeWithDeadline(deadline) {\n        // Read the time remaining from the `deadline` immediately because it is unclear\n        // if the `deadline` object will be valid after execution leaves this function.\n        const endTime = Date.now() + deadline.timeRemaining();\n        const execute = () => {\n            if (this._isDisposed || !this._textModel.isAttachedToEditor() || !this._hasLinesToTokenize()) {\n                // disposed in the meantime or detached or finished\n                return;\n            }\n            this._backgroundTokenizeForAtLeast1ms();\n            if (Date.now() < endTime) {\n                // There is still time before reaching the deadline, so yield to the browser and then\n                // continue execution\n                setTimeout0(execute);\n            }\n            else {\n                // The deadline has been reached, so schedule a new idle callback if necessary\n                this._beginBackgroundTokenization();\n            }\n        };\n        execute();\n    }\n    /**\n     * Tokenize for at least 1ms.\n     */\n    _backgroundTokenizeForAtLeast1ms() {\n        const lineCount = this._textModel.getLineCount();\n        const builder = new ContiguousMultilineTokensBuilder();\n        const sw = StopWatch.create(false);\n        do {\n            if (sw.elapsed() > 1) {\n                // the comparison is intentionally > 1 and not >= 1 to ensure that\n                // a full millisecond has elapsed, given how microseconds are rounded\n                // to milliseconds\n                break;\n            }\n            const tokenizedLineNumber = this._tokenizeOneInvalidLine(builder);\n            if (tokenizedLineNumber >= lineCount) {\n                break;\n            }\n        } while (this._hasLinesToTokenize());\n        this._tokenizationPart.setTokens(builder.finalize(), this._isTokenizationComplete());\n    }\n    tokenizeViewport(startLineNumber, endLineNumber) {\n        const builder = new ContiguousMultilineTokensBuilder();\n        this._tokenizeViewport(builder, startLineNumber, endLineNumber);\n        this._tokenizationPart.setTokens(builder.finalize(), this._isTokenizationComplete());\n    }\n    reset() {\n        this._resetTokenizationState();\n        this._tokenizationPart.clearTokens();\n    }\n    forceTokenization(lineNumber) {\n        const builder = new ContiguousMultilineTokensBuilder();\n        this._updateTokensUntilLine(builder, lineNumber);\n        this._tokenizationPart.setTokens(builder.finalize(), this._isTokenizationComplete());\n    }\n    getTokenTypeIfInsertingCharacter(position, character) {\n        if (!this._tokenizationStateStore) {\n            return 0 /* StandardTokenType.Other */;\n        }\n        this.forceTokenization(position.lineNumber);\n        const lineStartState = this._tokenizationStateStore.getBeginState(position.lineNumber - 1);\n        if (!lineStartState) {\n            return 0 /* StandardTokenType.Other */;\n        }\n        const languageId = this._textModel.getLanguageId();\n        const lineContent = this._textModel.getLineContent(position.lineNumber);\n        // Create the text as if `character` was inserted\n        const text = (lineContent.substring(0, position.column - 1)\n            + character\n            + lineContent.substring(position.column - 1));\n        const r = safeTokenize(this._languageIdCodec, languageId, this._tokenizationStateStore.tokenizationSupport, text, true, lineStartState);\n        const lineTokens = new LineTokens(r.tokens, text, this._languageIdCodec);\n        if (lineTokens.getCount() === 0) {\n            return 0 /* StandardTokenType.Other */;\n        }\n        const tokenIndex = lineTokens.findTokenIndexAtOffset(position.column - 1);\n        return lineTokens.getStandardTokenType(tokenIndex);\n    }\n    tokenizeLineWithEdit(position, length, newText) {\n        const lineNumber = position.lineNumber;\n        const column = position.column;\n        if (!this._tokenizationStateStore) {\n            return null;\n        }\n        this.forceTokenization(lineNumber);\n        const lineStartState = this._tokenizationStateStore.getBeginState(lineNumber - 1);\n        if (!lineStartState) {\n            return null;\n        }\n        const curLineContent = this._textModel.getLineContent(lineNumber);\n        const newLineContent = curLineContent.substring(0, column - 1)\n            + newText + curLineContent.substring(column - 1 + length);\n        const languageId = this._textModel.getLanguageIdAtPosition(lineNumber, 0);\n        const result = safeTokenize(this._languageIdCodec, languageId, this._tokenizationStateStore.tokenizationSupport, newLineContent, true, lineStartState);\n        const lineTokens = new LineTokens(result.tokens, newLineContent, this._languageIdCodec);\n        return lineTokens;\n    }\n    isCheapToTokenize(lineNumber) {\n        if (!this._tokenizationStateStore) {\n            return true;\n        }\n        const firstInvalidLineNumber = this._tokenizationStateStore.invalidLineStartIndex + 1;\n        if (lineNumber > firstInvalidLineNumber) {\n            return false;\n        }\n        if (lineNumber < firstInvalidLineNumber) {\n            return true;\n        }\n        if (this._textModel.getLineLength(lineNumber) < 2048 /* Constants.CHEAP_TOKENIZATION_LENGTH_LIMIT */) {\n            return true;\n        }\n        return false;\n    }\n    _hasLinesToTokenize() {\n        if (!this._tokenizationStateStore) {\n            return false;\n        }\n        return (this._tokenizationStateStore.invalidLineStartIndex < this._textModel.getLineCount());\n    }\n    _isTokenizationComplete() {\n        if (!this._tokenizationStateStore) {\n            return false;\n        }\n        return (this._tokenizationStateStore.invalidLineStartIndex >= this._textModel.getLineCount());\n    }\n    _tokenizeOneInvalidLine(builder) {\n        if (!this._tokenizationStateStore || !this._hasLinesToTokenize()) {\n            return this._textModel.getLineCount() + 1;\n        }\n        const lineNumber = this._tokenizationStateStore.invalidLineStartIndex + 1;\n        this._updateTokensUntilLine(builder, lineNumber);\n        return lineNumber;\n    }\n    _updateTokensUntilLine(builder, lineNumber) {\n        if (!this._tokenizationStateStore) {\n            return;\n        }\n        const languageId = this._textModel.getLanguageId();\n        const linesLength = this._textModel.getLineCount();\n        const endLineIndex = lineNumber - 1;\n        // Validate all states up to and including endLineIndex\n        for (let lineIndex = this._tokenizationStateStore.invalidLineStartIndex; lineIndex <= endLineIndex; lineIndex++) {\n            const text = this._textModel.getLineContent(lineIndex + 1);\n            const lineStartState = this._tokenizationStateStore.getBeginState(lineIndex);\n            const r = safeTokenize(this._languageIdCodec, languageId, this._tokenizationStateStore.tokenizationSupport, text, true, lineStartState);\n            builder.add(lineIndex + 1, r.tokens);\n            this._tokenizationStateStore.setEndState(linesLength, lineIndex, r.endState);\n            lineIndex = this._tokenizationStateStore.invalidLineStartIndex - 1; // -1 because the outer loop increments it\n        }\n    }\n    _tokenizeViewport(builder, startLineNumber, endLineNumber) {\n        if (!this._tokenizationStateStore) {\n            // nothing to do\n            return;\n        }\n        if (endLineNumber <= this._tokenizationStateStore.invalidLineStartIndex) {\n            // nothing to do\n            return;\n        }\n        if (startLineNumber <= this._tokenizationStateStore.invalidLineStartIndex) {\n            // tokenization has reached the viewport start...\n            this._updateTokensUntilLine(builder, endLineNumber);\n            return;\n        }\n        let nonWhitespaceColumn = this._textModel.getLineFirstNonWhitespaceColumn(startLineNumber);\n        const fakeLines = [];\n        let initialState = null;\n        for (let i = startLineNumber - 1; nonWhitespaceColumn > 1 && i >= 1; i--) {\n            const newNonWhitespaceIndex = this._textModel.getLineFirstNonWhitespaceColumn(i);\n            if (newNonWhitespaceIndex === 0) {\n                continue;\n            }\n            if (newNonWhitespaceIndex < nonWhitespaceColumn) {\n                fakeLines.push(this._textModel.getLineContent(i));\n                nonWhitespaceColumn = newNonWhitespaceIndex;\n                initialState = this._tokenizationStateStore.getBeginState(i - 1);\n                if (initialState) {\n                    break;\n                }\n            }\n        }\n        if (!initialState) {\n            initialState = this._tokenizationStateStore.initialState;\n        }\n        const languageId = this._textModel.getLanguageId();\n        let state = initialState;\n        for (let i = fakeLines.length - 1; i >= 0; i--) {\n            const r = safeTokenize(this._languageIdCodec, languageId, this._tokenizationStateStore.tokenizationSupport, fakeLines[i], false, state);\n            state = r.endState;\n        }\n        for (let lineNumber = startLineNumber; lineNumber <= endLineNumber; lineNumber++) {\n            const text = this._textModel.getLineContent(lineNumber);\n            const r = safeTokenize(this._languageIdCodec, languageId, this._tokenizationStateStore.tokenizationSupport, text, true, state);\n            builder.add(lineNumber, r.tokens);\n            this._tokenizationStateStore.markMustBeTokenized(lineNumber - 1);\n            state = r.endState;\n        }\n    }\n}\nfunction initializeTokenization(textModel, tokenizationPart) {\n    if (textModel.isTooLargeForTokenization()) {\n        return [null, null];\n    }\n    const tokenizationSupport = TokenizationRegistry.get(tokenizationPart.getLanguageId());\n    if (!tokenizationSupport) {\n        return [null, null];\n    }\n    let initialState;\n    try {\n        initialState = tokenizationSupport.getInitialState();\n    }\n    catch (e) {\n        onUnexpectedError(e);\n        return [null, null];\n    }\n    return [tokenizationSupport, initialState];\n}\nfunction safeTokenize(languageIdCodec, languageId, tokenizationSupport, text, hasEOL, state) {\n    let r = null;\n    if (tokenizationSupport) {\n        try {\n            r = tokenizationSupport.tokenizeEncoded(text, hasEOL, state.clone());\n        }\n        catch (e) {\n            onUnexpectedError(e);\n        }\n    }\n    if (!r) {\n        r = nullTokenizeEncoded(languageIdCodec.encodeLanguageId(languageId), state);\n    }\n    LineTokens.convertToEndOffset(r.tokens, text.length);\n    return r;\n}\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA,OAAO,KAAKA,MAAM,MAAM,gCAAgC;AACxD,SAASC,iBAAiB,QAAQ,gCAAgC;AAClE,SAASC,UAAU,QAAQ,yBAAyB;AACpD,SAASC,oBAAoB,QAAQ,iBAAiB;AACtD,SAASC,mBAAmB,QAAQ,8BAA8B;AAClE,SAASC,UAAU,QAAQ,mCAAmC;AAC9D,SAASC,SAAS,QAAQ,mCAAmC;AAC7D,SAASC,QAAQ,QAAQ,uBAAuB;AAChD,SAASC,gCAAgC,QAAQ,+CAA+C;AAChG,SAASC,WAAW,QAAQ,+BAA+B;AAC3D,SAASC,WAAW,QAAQ,kCAAkC;AAC9D;AACA;AACA;AACA;AACA,MAAMC,sBAAsB,CAAC;EACzBC,WAAW,CAACC,QAAQ,EAAE;IAClB,IAAI,CAACA,QAAQ,GAAGA,QAAQ;IACxB,IAAI,CAACC,MAAM,GAAG,EAAE;EACpB;EACAC,GAAG,CAACC,KAAK,EAAE;IACP,IAAIA,KAAK,GAAG,IAAI,CAACF,MAAM,CAACG,MAAM,EAAE;MAC5B,OAAO,IAAI,CAACH,MAAM,CAACE,KAAK,CAAC;IAC7B;IACA,OAAO,IAAI,CAACH,QAAQ;EACxB;EACAK,GAAG,CAACF,KAAK,EAAEG,KAAK,EAAE;IACd,OAAOH,KAAK,IAAI,IAAI,CAACF,MAAM,CAACG,MAAM,EAAE;MAChC,IAAI,CAACH,MAAM,CAAC,IAAI,CAACA,MAAM,CAACG,MAAM,CAAC,GAAG,IAAI,CAACJ,QAAQ;IACnD;IACA,IAAI,CAACC,MAAM,CAACE,KAAK,CAAC,GAAGG,KAAK;EAC9B;EACAC,MAAM,CAACC,WAAW,EAAEC,WAAW,EAAE;IAC7B,IAAIA,WAAW,KAAK,CAAC,IAAID,WAAW,IAAI,IAAI,CAACP,MAAM,CAACG,MAAM,EAAE;MACxD;IACJ;IACA,IAAI,CAACH,MAAM,CAACS,MAAM,CAACF,WAAW,EAAEC,WAAW,CAAC;EAChD;EACAE,MAAM,CAACC,WAAW,EAAEC,WAAW,EAAE;IAC7B,IAAIA,WAAW,KAAK,CAAC,IAAID,WAAW,IAAI,IAAI,CAACX,MAAM,CAACG,MAAM,EAAE;MACxD;IACJ;IACA,MAAMU,GAAG,GAAG,EAAE;IACd,KAAK,IAAIC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGF,WAAW,EAAEE,CAAC,EAAE,EAAE;MAClCD,GAAG,CAACC,CAAC,CAAC,GAAG,IAAI,CAACf,QAAQ;IAC1B;IACA,IAAI,CAACC,MAAM,GAAGd,MAAM,CAAC6B,WAAW,CAAC,IAAI,CAACf,MAAM,EAAEW,WAAW,EAAEE,GAAG,CAAC;EACnE;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMG,sBAAsB,CAAC;EAChClB,WAAW,CAACmB,mBAAmB,EAAEC,YAAY,EAAE;IAC3C,IAAI,CAACD,mBAAmB,GAAGA,mBAAmB;IAC9C,IAAI,CAACC,YAAY,GAAGA,YAAY;IAChC;AACR;AACA;IACQ,IAAI,CAACC,eAAe,GAAG,IAAItB,sBAAsB,CAAC,IAAI,CAAC;IACvD;AACR;AACA;IACQ,IAAI,CAACuB,sBAAsB,GAAG,IAAIvB,sBAAsB,CAAC,IAAI,CAAC;IAC9D,IAAI,CAACwB,2BAA2B,GAAG,CAAC;IACpC,IAAI,CAACF,eAAe,CAACf,GAAG,CAAC,CAAC,EAAE,IAAI,CAACc,YAAY,CAAC;EAClD;EACA,IAAII,qBAAqB,GAAG;IACxB,OAAO,IAAI,CAACD,2BAA2B;EAC3C;EACAE,mBAAmB,CAACC,SAAS,EAAE;IAC3B,IAAI,CAACJ,sBAAsB,CAAChB,GAAG,CAACoB,SAAS,EAAE,IAAI,CAAC;IAChD,IAAI,CAACH,2BAA2B,GAAGI,IAAI,CAACC,GAAG,CAAC,IAAI,CAACL,2BAA2B,EAAEG,SAAS,CAAC;EAC5F;EACAG,aAAa,CAACH,SAAS,EAAE;IACrB,OAAO,IAAI,CAACL,eAAe,CAAClB,GAAG,CAACuB,SAAS,CAAC;EAC9C;EACAI,WAAW,CAACC,WAAW,EAAEL,SAAS,EAAEM,QAAQ,EAAE;IAC1C,IAAI,CAACV,sBAAsB,CAAChB,GAAG,CAACoB,SAAS,EAAE,KAAK,CAAC;IACjD,IAAI,CAACH,2BAA2B,GAAGG,SAAS,GAAG,CAAC;IAChD;IACA,IAAIA,SAAS,KAAKK,WAAW,GAAG,CAAC,EAAE;MAC/B;IACJ;IACA;IACA,MAAME,gBAAgB,GAAG,IAAI,CAACZ,eAAe,CAAClB,GAAG,CAACuB,SAAS,GAAG,CAAC,CAAC;IAChE,IAAIO,gBAAgB,KAAK,IAAI,IAAI,CAACD,QAAQ,CAACE,MAAM,CAACD,gBAAgB,CAAC,EAAE;MACjE,IAAI,CAACZ,eAAe,CAACf,GAAG,CAACoB,SAAS,GAAG,CAAC,EAAEM,QAAQ,CAAC;MACjD,IAAI,CAACP,mBAAmB,CAACC,SAAS,GAAG,CAAC,CAAC;MACvC;IACJ;IACA;IACA,IAAIV,CAAC,GAAGU,SAAS,GAAG,CAAC;IACrB,OAAOV,CAAC,GAAGe,WAAW,EAAE;MACpB,IAAI,IAAI,CAACT,sBAAsB,CAACnB,GAAG,CAACa,CAAC,CAAC,EAAE;QACpC;MACJ;MACAA,CAAC,EAAE;IACP;IACA,IAAI,CAACO,2BAA2B,GAAGP,CAAC;EACxC;EACA;EACAmB,UAAU,CAACC,KAAK,EAAEC,QAAQ,EAAE;IACxB,IAAI,CAACZ,mBAAmB,CAACW,KAAK,CAACE,eAAe,GAAG,CAAC,CAAC;IACnD,IAAI,CAACjB,eAAe,CAACb,MAAM,CAAC4B,KAAK,CAACE,eAAe,EAAEF,KAAK,CAACG,aAAa,GAAGH,KAAK,CAACE,eAAe,CAAC;IAC/F,IAAI,CAAChB,sBAAsB,CAACd,MAAM,CAAC4B,KAAK,CAACE,eAAe,EAAEF,KAAK,CAACG,aAAa,GAAGH,KAAK,CAACE,eAAe,CAAC;IACtG,IAAI,CAACjB,eAAe,CAACT,MAAM,CAACwB,KAAK,CAACE,eAAe,EAAED,QAAQ,CAAC;IAC5D,IAAI,CAACf,sBAAsB,CAACV,MAAM,CAACwB,KAAK,CAACE,eAAe,EAAED,QAAQ,CAAC;EACvE;AACJ;AACA,OAAO,MAAMG,qBAAqB,SAAS/C,UAAU,CAAC;EAClDO,WAAW,CAACyC,UAAU,EAAEC,iBAAiB,EAAEC,gBAAgB,EAAE;IACzD,KAAK,EAAE;IACP,IAAI,CAACF,UAAU,GAAGA,UAAU;IAC5B,IAAI,CAACC,iBAAiB,GAAGA,iBAAiB;IAC1C,IAAI,CAACC,gBAAgB,GAAGA,gBAAgB;IACxC,IAAI,CAACC,YAAY,GAAG,KAAK;IACzB,IAAI,CAACC,WAAW,GAAG,KAAK;IACxB,IAAI,CAACC,uBAAuB,GAAG,IAAI;IACnC,IAAI,CAACC,SAAS,CAACxD,oBAAoB,CAACyD,WAAW,CAAEC,CAAC,IAAK;MACnD,MAAMC,UAAU,GAAG,IAAI,CAACT,UAAU,CAACU,aAAa,EAAE;MAClD,IAAIF,CAAC,CAACG,gBAAgB,CAACC,OAAO,CAACH,UAAU,CAAC,KAAK,CAAC,CAAC,EAAE;QAC/C;MACJ;MACA,IAAI,CAACI,uBAAuB,EAAE;MAC9B,IAAI,CAACZ,iBAAiB,CAACa,WAAW,EAAE;IACxC,CAAC,CAAC,CAAC;IACH,IAAI,CAACD,uBAAuB,EAAE;EAClC;EACAE,OAAO,GAAG;IACN,IAAI,CAACX,WAAW,GAAG,IAAI;IACvB,KAAK,CAACW,OAAO,EAAE;EACnB;EACA;EACAC,sBAAsB,CAACR,CAAC,EAAE;IACtB,IAAIA,CAAC,CAACS,OAAO,EAAE;MACX,IAAI,CAACJ,uBAAuB,EAAE;MAC9B;IACJ;IACA,IAAI,IAAI,CAACR,uBAAuB,EAAE;MAC9B,KAAK,IAAI9B,CAAC,GAAG,CAAC,EAAE2C,GAAG,GAAGV,CAAC,CAACW,OAAO,CAACvD,MAAM,EAAEW,CAAC,GAAG2C,GAAG,EAAE3C,CAAC,EAAE,EAAE;QAClD,MAAM6C,MAAM,GAAGZ,CAAC,CAACW,OAAO,CAAC5C,CAAC,CAAC;QAC3B,MAAM,CAACqB,QAAQ,CAAC,GAAG1C,QAAQ,CAACkE,MAAM,CAACC,IAAI,CAAC;QACxC,IAAI,CAAChB,uBAAuB,CAACX,UAAU,CAAC0B,MAAM,CAACzB,KAAK,EAAEC,QAAQ,CAAC;MACnE;IACJ;IACA,IAAI,CAAC0B,4BAA4B,EAAE;EACvC;EACAC,uBAAuB,GAAG;IACtB,IAAI,CAACD,4BAA4B,EAAE;EACvC;EACAE,uBAAuB,CAAChB,CAAC,EAAE;IACvB,IAAI,CAACK,uBAAuB,EAAE;IAC9B,IAAI,CAACZ,iBAAiB,CAACa,WAAW,EAAE;EACxC;EACA;EACAD,uBAAuB,GAAG;IACtB,MAAM,CAACnC,mBAAmB,EAAEC,YAAY,CAAC,GAAG8C,sBAAsB,CAAC,IAAI,CAACzB,UAAU,EAAE,IAAI,CAACC,iBAAiB,CAAC;IAC3G,IAAIvB,mBAAmB,IAAIC,YAAY,EAAE;MACrC,IAAI,CAAC0B,uBAAuB,GAAG,IAAI5B,sBAAsB,CAACC,mBAAmB,EAAEC,YAAY,CAAC;IAChG,CAAC,MACI;MACD,IAAI,CAAC0B,uBAAuB,GAAG,IAAI;IACvC;IACA,IAAI,CAACiB,4BAA4B,EAAE;EACvC;EACAA,4BAA4B,GAAG;IAC3B,IAAI,IAAI,CAACnB,YAAY,IAAI,CAAC,IAAI,CAACH,UAAU,CAAC0B,kBAAkB,EAAE,IAAI,CAAC,IAAI,CAACC,mBAAmB,EAAE,EAAE;MAC3F;IACJ;IACA,IAAI,CAACxB,YAAY,GAAG,IAAI;IACxB/C,WAAW,CAAEwE,QAAQ,IAAK;MACtB,IAAI,CAACzB,YAAY,GAAG,KAAK;MACzB,IAAI,CAAC0B,+BAA+B,CAACD,QAAQ,CAAC;IAClD,CAAC,CAAC;EACN;EACA;AACJ;AACA;EACIC,+BAA+B,CAACD,QAAQ,EAAE;IACtC;IACA;IACA,MAAME,OAAO,GAAGC,IAAI,CAACC,GAAG,EAAE,GAAGJ,QAAQ,CAACK,aAAa,EAAE;IACrD,MAAMC,OAAO,GAAG,MAAM;MAClB,IAAI,IAAI,CAAC9B,WAAW,IAAI,CAAC,IAAI,CAACJ,UAAU,CAAC0B,kBAAkB,EAAE,IAAI,CAAC,IAAI,CAACC,mBAAmB,EAAE,EAAE;QAC1F;QACA;MACJ;MACA,IAAI,CAACQ,gCAAgC,EAAE;MACvC,IAAIJ,IAAI,CAACC,GAAG,EAAE,GAAGF,OAAO,EAAE;QACtB;QACA;QACAzE,WAAW,CAAC6E,OAAO,CAAC;MACxB,CAAC,MACI;QACD;QACA,IAAI,CAACZ,4BAA4B,EAAE;MACvC;IACJ,CAAC;IACDY,OAAO,EAAE;EACb;EACA;AACJ;AACA;EACIC,gCAAgC,GAAG;IAC/B,MAAMC,SAAS,GAAG,IAAI,CAACpC,UAAU,CAACqC,YAAY,EAAE;IAChD,MAAMC,OAAO,GAAG,IAAInF,gCAAgC,EAAE;IACtD,MAAMoF,EAAE,GAAGtF,SAAS,CAACuF,MAAM,CAAC,KAAK,CAAC;IAClC,GAAG;MACC,IAAID,EAAE,CAACE,OAAO,EAAE,GAAG,CAAC,EAAE;QAClB;QACA;QACA;QACA;MACJ;MACA,MAAMC,mBAAmB,GAAG,IAAI,CAACC,uBAAuB,CAACL,OAAO,CAAC;MACjE,IAAII,mBAAmB,IAAIN,SAAS,EAAE;QAClC;MACJ;IACJ,CAAC,QAAQ,IAAI,CAACT,mBAAmB,EAAE;IACnC,IAAI,CAAC1B,iBAAiB,CAAC2C,SAAS,CAACN,OAAO,CAACO,QAAQ,EAAE,EAAE,IAAI,CAACC,uBAAuB,EAAE,CAAC;EACxF;EACAC,gBAAgB,CAAClD,eAAe,EAAEC,aAAa,EAAE;IAC7C,MAAMwC,OAAO,GAAG,IAAInF,gCAAgC,EAAE;IACtD,IAAI,CAAC6F,iBAAiB,CAACV,OAAO,EAAEzC,eAAe,EAAEC,aAAa,CAAC;IAC/D,IAAI,CAACG,iBAAiB,CAAC2C,SAAS,CAACN,OAAO,CAACO,QAAQ,EAAE,EAAE,IAAI,CAACC,uBAAuB,EAAE,CAAC;EACxF;EACAG,KAAK,GAAG;IACJ,IAAI,CAACpC,uBAAuB,EAAE;IAC9B,IAAI,CAACZ,iBAAiB,CAACa,WAAW,EAAE;EACxC;EACAoC,iBAAiB,CAACC,UAAU,EAAE;IAC1B,MAAMb,OAAO,GAAG,IAAInF,gCAAgC,EAAE;IACtD,IAAI,CAACiG,sBAAsB,CAACd,OAAO,EAAEa,UAAU,CAAC;IAChD,IAAI,CAAClD,iBAAiB,CAAC2C,SAAS,CAACN,OAAO,CAACO,QAAQ,EAAE,EAAE,IAAI,CAACC,uBAAuB,EAAE,CAAC;EACxF;EACAO,gCAAgC,CAACC,QAAQ,EAAEC,SAAS,EAAE;IAClD,IAAI,CAAC,IAAI,CAAClD,uBAAuB,EAAE;MAC/B,OAAO,CAAC,CAAC;IACb;;IACA,IAAI,CAAC6C,iBAAiB,CAACI,QAAQ,CAACH,UAAU,CAAC;IAC3C,MAAMK,cAAc,GAAG,IAAI,CAACnD,uBAAuB,CAACjB,aAAa,CAACkE,QAAQ,CAACH,UAAU,GAAG,CAAC,CAAC;IAC1F,IAAI,CAACK,cAAc,EAAE;MACjB,OAAO,CAAC,CAAC;IACb;;IACA,MAAM/C,UAAU,GAAG,IAAI,CAACT,UAAU,CAACU,aAAa,EAAE;IAClD,MAAM+C,WAAW,GAAG,IAAI,CAACzD,UAAU,CAAC0D,cAAc,CAACJ,QAAQ,CAACH,UAAU,CAAC;IACvE;IACA,MAAM9B,IAAI,GAAIoC,WAAW,CAACE,SAAS,CAAC,CAAC,EAAEL,QAAQ,CAACM,MAAM,GAAG,CAAC,CAAC,GACrDL,SAAS,GACTE,WAAW,CAACE,SAAS,CAACL,QAAQ,CAACM,MAAM,GAAG,CAAC,CAAE;IACjD,MAAMC,CAAC,GAAGC,YAAY,CAAC,IAAI,CAAC5D,gBAAgB,EAAEO,UAAU,EAAE,IAAI,CAACJ,uBAAuB,CAAC3B,mBAAmB,EAAE2C,IAAI,EAAE,IAAI,EAAEmC,cAAc,CAAC;IACvI,MAAMO,UAAU,GAAG,IAAIlH,UAAU,CAACgH,CAAC,CAACG,MAAM,EAAE3C,IAAI,EAAE,IAAI,CAACnB,gBAAgB,CAAC;IACxE,IAAI6D,UAAU,CAACE,QAAQ,EAAE,KAAK,CAAC,EAAE;MAC7B,OAAO,CAAC,CAAC;IACb;;IACA,MAAMC,UAAU,GAAGH,UAAU,CAACI,sBAAsB,CAACb,QAAQ,CAACM,MAAM,GAAG,CAAC,CAAC;IACzE,OAAOG,UAAU,CAACK,oBAAoB,CAACF,UAAU,CAAC;EACtD;EACAG,oBAAoB,CAACf,QAAQ,EAAE1F,MAAM,EAAE0G,OAAO,EAAE;IAC5C,MAAMnB,UAAU,GAAGG,QAAQ,CAACH,UAAU;IACtC,MAAMS,MAAM,GAAGN,QAAQ,CAACM,MAAM;IAC9B,IAAI,CAAC,IAAI,CAACvD,uBAAuB,EAAE;MAC/B,OAAO,IAAI;IACf;IACA,IAAI,CAAC6C,iBAAiB,CAACC,UAAU,CAAC;IAClC,MAAMK,cAAc,GAAG,IAAI,CAACnD,uBAAuB,CAACjB,aAAa,CAAC+D,UAAU,GAAG,CAAC,CAAC;IACjF,IAAI,CAACK,cAAc,EAAE;MACjB,OAAO,IAAI;IACf;IACA,MAAMe,cAAc,GAAG,IAAI,CAACvE,UAAU,CAAC0D,cAAc,CAACP,UAAU,CAAC;IACjE,MAAMqB,cAAc,GAAGD,cAAc,CAACZ,SAAS,CAAC,CAAC,EAAEC,MAAM,GAAG,CAAC,CAAC,GACxDU,OAAO,GAAGC,cAAc,CAACZ,SAAS,CAACC,MAAM,GAAG,CAAC,GAAGhG,MAAM,CAAC;IAC7D,MAAM6C,UAAU,GAAG,IAAI,CAACT,UAAU,CAACyE,uBAAuB,CAACtB,UAAU,EAAE,CAAC,CAAC;IACzE,MAAMuB,MAAM,GAAGZ,YAAY,CAAC,IAAI,CAAC5D,gBAAgB,EAAEO,UAAU,EAAE,IAAI,CAACJ,uBAAuB,CAAC3B,mBAAmB,EAAE8F,cAAc,EAAE,IAAI,EAAEhB,cAAc,CAAC;IACtJ,MAAMO,UAAU,GAAG,IAAIlH,UAAU,CAAC6H,MAAM,CAACV,MAAM,EAAEQ,cAAc,EAAE,IAAI,CAACtE,gBAAgB,CAAC;IACvF,OAAO6D,UAAU;EACrB;EACAY,iBAAiB,CAACxB,UAAU,EAAE;IAC1B,IAAI,CAAC,IAAI,CAAC9C,uBAAuB,EAAE;MAC/B,OAAO,IAAI;IACf;IACA,MAAMuE,sBAAsB,GAAG,IAAI,CAACvE,uBAAuB,CAACtB,qBAAqB,GAAG,CAAC;IACrF,IAAIoE,UAAU,GAAGyB,sBAAsB,EAAE;MACrC,OAAO,KAAK;IAChB;IACA,IAAIzB,UAAU,GAAGyB,sBAAsB,EAAE;MACrC,OAAO,IAAI;IACf;IACA,IAAI,IAAI,CAAC5E,UAAU,CAAC6E,aAAa,CAAC1B,UAAU,CAAC,GAAG,IAAI,CAAC,iDAAiD;MAClG,OAAO,IAAI;IACf;IACA,OAAO,KAAK;EAChB;EACAxB,mBAAmB,GAAG;IAClB,IAAI,CAAC,IAAI,CAACtB,uBAAuB,EAAE;MAC/B,OAAO,KAAK;IAChB;IACA,OAAQ,IAAI,CAACA,uBAAuB,CAACtB,qBAAqB,GAAG,IAAI,CAACiB,UAAU,CAACqC,YAAY,EAAE;EAC/F;EACAS,uBAAuB,GAAG;IACtB,IAAI,CAAC,IAAI,CAACzC,uBAAuB,EAAE;MAC/B,OAAO,KAAK;IAChB;IACA,OAAQ,IAAI,CAACA,uBAAuB,CAACtB,qBAAqB,IAAI,IAAI,CAACiB,UAAU,CAACqC,YAAY,EAAE;EAChG;EACAM,uBAAuB,CAACL,OAAO,EAAE;IAC7B,IAAI,CAAC,IAAI,CAACjC,uBAAuB,IAAI,CAAC,IAAI,CAACsB,mBAAmB,EAAE,EAAE;MAC9D,OAAO,IAAI,CAAC3B,UAAU,CAACqC,YAAY,EAAE,GAAG,CAAC;IAC7C;IACA,MAAMc,UAAU,GAAG,IAAI,CAAC9C,uBAAuB,CAACtB,qBAAqB,GAAG,CAAC;IACzE,IAAI,CAACqE,sBAAsB,CAACd,OAAO,EAAEa,UAAU,CAAC;IAChD,OAAOA,UAAU;EACrB;EACAC,sBAAsB,CAACd,OAAO,EAAEa,UAAU,EAAE;IACxC,IAAI,CAAC,IAAI,CAAC9C,uBAAuB,EAAE;MAC/B;IACJ;IACA,MAAMI,UAAU,GAAG,IAAI,CAACT,UAAU,CAACU,aAAa,EAAE;IAClD,MAAMpB,WAAW,GAAG,IAAI,CAACU,UAAU,CAACqC,YAAY,EAAE;IAClD,MAAMyC,YAAY,GAAG3B,UAAU,GAAG,CAAC;IACnC;IACA,KAAK,IAAIlE,SAAS,GAAG,IAAI,CAACoB,uBAAuB,CAACtB,qBAAqB,EAAEE,SAAS,IAAI6F,YAAY,EAAE7F,SAAS,EAAE,EAAE;MAC7G,MAAMoC,IAAI,GAAG,IAAI,CAACrB,UAAU,CAAC0D,cAAc,CAACzE,SAAS,GAAG,CAAC,CAAC;MAC1D,MAAMuE,cAAc,GAAG,IAAI,CAACnD,uBAAuB,CAACjB,aAAa,CAACH,SAAS,CAAC;MAC5E,MAAM4E,CAAC,GAAGC,YAAY,CAAC,IAAI,CAAC5D,gBAAgB,EAAEO,UAAU,EAAE,IAAI,CAACJ,uBAAuB,CAAC3B,mBAAmB,EAAE2C,IAAI,EAAE,IAAI,EAAEmC,cAAc,CAAC;MACvIlB,OAAO,CAACyC,GAAG,CAAC9F,SAAS,GAAG,CAAC,EAAE4E,CAAC,CAACG,MAAM,CAAC;MACpC,IAAI,CAAC3D,uBAAuB,CAAChB,WAAW,CAACC,WAAW,EAAEL,SAAS,EAAE4E,CAAC,CAACtE,QAAQ,CAAC;MAC5EN,SAAS,GAAG,IAAI,CAACoB,uBAAuB,CAACtB,qBAAqB,GAAG,CAAC,CAAC,CAAC;IACxE;EACJ;;EACAiE,iBAAiB,CAACV,OAAO,EAAEzC,eAAe,EAAEC,aAAa,EAAE;IACvD,IAAI,CAAC,IAAI,CAACO,uBAAuB,EAAE;MAC/B;MACA;IACJ;IACA,IAAIP,aAAa,IAAI,IAAI,CAACO,uBAAuB,CAACtB,qBAAqB,EAAE;MACrE;MACA;IACJ;IACA,IAAIc,eAAe,IAAI,IAAI,CAACQ,uBAAuB,CAACtB,qBAAqB,EAAE;MACvE;MACA,IAAI,CAACqE,sBAAsB,CAACd,OAAO,EAAExC,aAAa,CAAC;MACnD;IACJ;IACA,IAAIkF,mBAAmB,GAAG,IAAI,CAAChF,UAAU,CAACiF,+BAA+B,CAACpF,eAAe,CAAC;IAC1F,MAAMqF,SAAS,GAAG,EAAE;IACpB,IAAIvG,YAAY,GAAG,IAAI;IACvB,KAAK,IAAIJ,CAAC,GAAGsB,eAAe,GAAG,CAAC,EAAEmF,mBAAmB,GAAG,CAAC,IAAIzG,CAAC,IAAI,CAAC,EAAEA,CAAC,EAAE,EAAE;MACtE,MAAM4G,qBAAqB,GAAG,IAAI,CAACnF,UAAU,CAACiF,+BAA+B,CAAC1G,CAAC,CAAC;MAChF,IAAI4G,qBAAqB,KAAK,CAAC,EAAE;QAC7B;MACJ;MACA,IAAIA,qBAAqB,GAAGH,mBAAmB,EAAE;QAC7CE,SAAS,CAACE,IAAI,CAAC,IAAI,CAACpF,UAAU,CAAC0D,cAAc,CAACnF,CAAC,CAAC,CAAC;QACjDyG,mBAAmB,GAAGG,qBAAqB;QAC3CxG,YAAY,GAAG,IAAI,CAAC0B,uBAAuB,CAACjB,aAAa,CAACb,CAAC,GAAG,CAAC,CAAC;QAChE,IAAII,YAAY,EAAE;UACd;QACJ;MACJ;IACJ;IACA,IAAI,CAACA,YAAY,EAAE;MACfA,YAAY,GAAG,IAAI,CAAC0B,uBAAuB,CAAC1B,YAAY;IAC5D;IACA,MAAM8B,UAAU,GAAG,IAAI,CAACT,UAAU,CAACU,aAAa,EAAE;IAClD,IAAI2E,KAAK,GAAG1G,YAAY;IACxB,KAAK,IAAIJ,CAAC,GAAG2G,SAAS,CAACtH,MAAM,GAAG,CAAC,EAAEW,CAAC,IAAI,CAAC,EAAEA,CAAC,EAAE,EAAE;MAC5C,MAAMsF,CAAC,GAAGC,YAAY,CAAC,IAAI,CAAC5D,gBAAgB,EAAEO,UAAU,EAAE,IAAI,CAACJ,uBAAuB,CAAC3B,mBAAmB,EAAEwG,SAAS,CAAC3G,CAAC,CAAC,EAAE,KAAK,EAAE8G,KAAK,CAAC;MACvIA,KAAK,GAAGxB,CAAC,CAACtE,QAAQ;IACtB;IACA,KAAK,IAAI4D,UAAU,GAAGtD,eAAe,EAAEsD,UAAU,IAAIrD,aAAa,EAAEqD,UAAU,EAAE,EAAE;MAC9E,MAAM9B,IAAI,GAAG,IAAI,CAACrB,UAAU,CAAC0D,cAAc,CAACP,UAAU,CAAC;MACvD,MAAMU,CAAC,GAAGC,YAAY,CAAC,IAAI,CAAC5D,gBAAgB,EAAEO,UAAU,EAAE,IAAI,CAACJ,uBAAuB,CAAC3B,mBAAmB,EAAE2C,IAAI,EAAE,IAAI,EAAEgE,KAAK,CAAC;MAC9H/C,OAAO,CAACyC,GAAG,CAAC5B,UAAU,EAAEU,CAAC,CAACG,MAAM,CAAC;MACjC,IAAI,CAAC3D,uBAAuB,CAACrB,mBAAmB,CAACmE,UAAU,GAAG,CAAC,CAAC;MAChEkC,KAAK,GAAGxB,CAAC,CAACtE,QAAQ;IACtB;EACJ;AACJ;AACA,SAASkC,sBAAsB,CAAC6D,SAAS,EAAEC,gBAAgB,EAAE;EACzD,IAAID,SAAS,CAACE,yBAAyB,EAAE,EAAE;IACvC,OAAO,CAAC,IAAI,EAAE,IAAI,CAAC;EACvB;EACA,MAAM9G,mBAAmB,GAAG5B,oBAAoB,CAACY,GAAG,CAAC6H,gBAAgB,CAAC7E,aAAa,EAAE,CAAC;EACtF,IAAI,CAAChC,mBAAmB,EAAE;IACtB,OAAO,CAAC,IAAI,EAAE,IAAI,CAAC;EACvB;EACA,IAAIC,YAAY;EAChB,IAAI;IACAA,YAAY,GAAGD,mBAAmB,CAAC+G,eAAe,EAAE;EACxD,CAAC,CACD,OAAOjF,CAAC,EAAE;IACN5D,iBAAiB,CAAC4D,CAAC,CAAC;IACpB,OAAO,CAAC,IAAI,EAAE,IAAI,CAAC;EACvB;EACA,OAAO,CAAC9B,mBAAmB,EAAEC,YAAY,CAAC;AAC9C;AACA,SAASmF,YAAY,CAAC4B,eAAe,EAAEjF,UAAU,EAAE/B,mBAAmB,EAAE2C,IAAI,EAAEsE,MAAM,EAAEN,KAAK,EAAE;EACzF,IAAIxB,CAAC,GAAG,IAAI;EACZ,IAAInF,mBAAmB,EAAE;IACrB,IAAI;MACAmF,CAAC,GAAGnF,mBAAmB,CAACkH,eAAe,CAACvE,IAAI,EAAEsE,MAAM,EAAEN,KAAK,CAACQ,KAAK,EAAE,CAAC;IACxE,CAAC,CACD,OAAOrF,CAAC,EAAE;MACN5D,iBAAiB,CAAC4D,CAAC,CAAC;IACxB;EACJ;EACA,IAAI,CAACqD,CAAC,EAAE;IACJA,CAAC,GAAG9G,mBAAmB,CAAC2I,eAAe,CAACI,gBAAgB,CAACrF,UAAU,CAAC,EAAE4E,KAAK,CAAC;EAChF;EACAxI,UAAU,CAACkJ,kBAAkB,CAAClC,CAAC,CAACG,MAAM,EAAE3C,IAAI,CAACzD,MAAM,CAAC;EACpD,OAAOiG,CAAC;AACZ"},"metadata":{},"sourceType":"module","externalDependencies":[]}